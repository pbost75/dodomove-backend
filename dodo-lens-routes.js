// ===============================================
// ROUTES DODO-LENS - SÃ‰CURISATION OPENAI
// ===============================================

const express = require('express');
const OpenAI = require('openai');
const multer = require('multer');
const rateLimit = require('express-rate-limit');
const crypto = require('crypto');

const router = express.Router();

// Configuration OpenAI avec debug avancÃ© et fallbacks pour Railway
let openai;
try {
  // Essayer plusieurs noms de variables Ã  cause des bugs Railway
  let apiKey = process.env.OPENAI_API_KEY || 
               process.env.OPENAI_KEY || 
               process.env.DODO_OPENAI_KEY ||
               process.env.OPENAI_SECRET;
               
  // Si pas de clÃ© directe, essayer la version Base64 encodÃ©e
  if (!apiKey && process.env.OPENAI_KEY_B64) {
    try {
      apiKey = Buffer.from(process.env.OPENAI_KEY_B64, 'base64').toString('utf8');
      console.log('ðŸ” ClÃ© OpenAI dÃ©codÃ©e depuis Base64');
    } catch (error) {
      console.error('âŒ Erreur dÃ©codage Base64:', error.message);
    }
  }
  
  console.log('ðŸ” Debug OpenAI Key Variables:', {
    OPENAI_API_KEY: !!process.env.OPENAI_API_KEY,
    OPENAI_KEY: !!process.env.OPENAI_KEY,
    DODO_OPENAI_KEY: !!process.env.DODO_OPENAI_KEY,
    OPENAI_SECRET: !!process.env.OPENAI_SECRET,
    selected_key_exists: !!apiKey,
    selected_key_length: apiKey ? apiKey.length : 0,
    selected_key_starts: apiKey ? apiKey.substring(0, 7) : 'N/A',
    selected_key_ends: apiKey ? '...' + apiKey.substring(apiKey.length - 4) : 'N/A'
  });
  
  if (!apiKey || apiKey.trim() === '') {
    console.log('âš ï¸ OPENAI_API_KEY non configurÃ©e - Routes DodoLens en mode dÃ©gradÃ©');
    openai = null;
  } else {
    const cleanedKey = apiKey.trim();
    openai = new OpenAI({
      apiKey: cleanedKey
    });
    console.log('âœ… OpenAI SDK initialisÃ© pour DodoLens avec clÃ© valide');
  }
} catch (error) {
  console.error('âŒ Erreur initialisation OpenAI SDK:', error.message);
  console.log('ðŸ”„ Routes DodoLens disponibles en mode dÃ©gradÃ©');
  openai = null;
}

// Rate limiting spÃ©cifique pour DodoLens
const dodoLensLimiter = rateLimit({
  windowMs: 24 * 60 * 60 * 1000, // 24 heures
  max: 10, // 10 requÃªtes par IP par jour
  message: {
    error: 'Limite quotidienne DodoLens atteinte (10 analyses/jour)',
    retryAfter: '24h',
    contact: 'Support technique disponible si besoin'
  },
  standardHeaders: true,
  legacyHeaders: false,
  trustProxy: true // FIX RAILWAY: Trust proxy headers pour X-Forwarded-For
  // Pas de keyGenerator personnalisÃ© = utilise req.ip par dÃ©faut (gÃ¨re IPv6 correctement)
});

// Middleware upload pour audio (mÃ©moire temporaire)
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { 
    fileSize: 25 * 1024 * 1024, // 25MB max (gÃ©nÃ©reusement pour vidÃ©os audio longues)
    files: 1
  },
  fileFilter: (req, file, cb) => {
    console.log('ðŸ” FileFilter - MIME reÃ§u:', file.mimetype || 'undefined');
    // MOBILE FIX: Accepter TOUS les fichiers car mobile peut envoyer MIME vide
    // On validera le contenu cÃ´tÃ© OpenAI plutÃ´t qu'ici
    cb(null, true);
  }
});

// ===============================================
// MIDDLEWARE JSON POUR ROUTES DODO-LENS
// ===============================================
router.use(express.json({ limit: '50mb' })); // Middleware JSON pour parser req.body - FIX v1.1

// ===============================================
// ROUTE EXPÃ‰RIMENTALE: AUDIO RAW (BYPASS MULTER)
// ===============================================
router.post('/analyze-audio-raw', dodoLensLimiter, express.raw({type: 'audio/*', limit: '25mb'}), async (req, res) => {
  // VÃ©rification OpenAI inline car requireOpenAI pas encore dÃ©fini
  if (!openai) {
    return res.status(503).json({ 
      error: 'Service OpenAI temporairement indisponible',
      status: 'retry_later'
    });
  }
  
  // POLYFILL FILE GLOBAL pour route RAW (SOLUTION DÃ‰FINITIVE)
  if (!globalThis.File) {
    try {
      const { File } = await import('node:buffer');
      globalThis.File = File;
      console.log('âœ… File global dÃ©fini pour route RAW');
    } catch (error) {
      console.log('âš ï¸ node:buffer non disponible, polyfill custom...');
      // Polyfill simple si node:buffer Ã©choue
      globalThis.File = class File {
        constructor(parts, name, options = {}) {
          this.name = name;
          this.type = options.type || '';
          this.buffer = Buffer.concat(parts.map(p => Buffer.from(p)));
          this.size = this.buffer.length;
        }
        stream() {
          const { Readable } = require('stream');
          return Readable.from(this.buffer);
        }
      };
      console.log('âœ… File polyfill custom installÃ©');
    }
  }
  
  try {
    const startTime = Date.now();
    
    console.log('ðŸŽ™ï¸ Audio RAW reÃ§u - BYPASS MULTER COMPLET:', {
      body_type: typeof req.body,
      body_constructor: req.body.constructor.name,
      body_length: req.body.length,
      content_type: req.headers['content-type']
    });
    
    // Validation basique
    if (!req.body || req.body.length === 0) {
      throw new Error('Aucun fichier audio reÃ§u');
    }
    
    // Le req.body EST DÃ‰JÃ€ UN BUFFER avec express.raw !
    const audioBuffer = req.body;
    console.log('âœ… Buffer direct depuis express.raw:', audioBuffer.length, 'bytes');
    
    // CrÃ©er fichier temporaire DIRECTEMENT
    const fs = require('fs');
    const path = require('path');
    const os = require('os');
    
    const tempFileName = `whisper_raw_${Date.now()}.webm`;
    const tempFilePath = path.join(os.tmpdir(), tempFileName);
    
    console.log('ðŸ’¾ Ã‰criture directe Buffer â†’ fichier temporaire');
    fs.writeFileSync(tempFilePath, audioBuffer);
    
    console.log('ðŸ“Š Fichier temporaire RAW crÃ©Ã©:', {
      path: tempFilePath,
      size: audioBuffer.length,
      exists: fs.existsSync(tempFilePath)
    });
    
    // Appel OpenAI Whisper SANS CONVERSION
    console.log('ðŸš€ OpenAI Whisper (mÃ©thode RAW - sans conversion)...');
    
    let response;
    try {
      const audioFileStream = fs.createReadStream(tempFilePath);
      audioFileStream.path = tempFilePath;
      
      response = await openai.audio.transcriptions.create({
        file: audioFileStream,
        model: "whisper-1",
        language: "fr",
        response_format: "json",
        temperature: 0.1
      });
      
      console.log('ðŸŽ‰ SUCCESS RAW! Texte transcrit:', response.text);
      
    } finally {
      // Cleanup
      try {
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
          console.log('ðŸ—‘ï¸ Fichier temporaire RAW supprimÃ©');
        }
      } catch (cleanupError) {
        console.log('âš ï¸ Erreur cleanup:', cleanupError.message);
      }
    }
    
    // Retourner rÃ©sultats
    const processingTime = Date.now() - startTime;
    const cost = calculateOpenAICost('whisper-1', { file_size: audioBuffer.length });
    
    res.json({
      success: true,
      transcript: response.text,
      method: 'raw-bypass-multer',
      usage: {
        file_size: audioBuffer.length,
        cost: Math.round(cost * 10000) / 10000,
        processing_time_ms: processingTime,
        transcript_length: response.text.length
      }
    });
    
  } catch (error) {
    console.error('âŒ Whisper RAW Error:', error);
    res.status(500).json({ 
      error: 'Erreur transcription RAW',
      details: error.message
    });
  }
});

// ===============================================
// MIDDLEWARE DE VÃ‰RIFICATION OPENAI
// ===============================================
const requireOpenAI = (req, res, next) => {
  if (!openai) {
    return res.status(503).json({ 
      error: 'Service DodoLens temporairement indisponible',
      details: 'Configuration OpenAI manquante - Contactez le support',
      debug: {
        hasEnvVar: !!process.env.OPENAI_API_KEY,
        envVarLength: process.env.OPENAI_API_KEY ? process.env.OPENAI_API_KEY.length : 0
      }
    });
  }
  next();
};

// ===============================================
// ROUTE 1: ANALYSE VISION (FRAMES VIDÃ‰O)
// ===============================================
router.post('/analyze-vision', dodoLensLimiter, requireOpenAI, async (req, res) => {
  try {
    const { imageData, prompt } = req.body;
    
    // Validation des donnÃ©es
    if (!imageData || !prompt) {
      return res.status(400).json({ 
        error: 'imageData et prompt requis',
        received: {
          hasImageData: !!imageData,
          hasPrompt: !!prompt
        }
      });
    }
    
    // Validation format image
    if (!imageData.startsWith('data:image/')) {
      return res.status(400).json({ 
        error: 'imageData doit Ãªtre au format data:image/...' 
      });
    }
    
    console.log('ðŸ”„ DodoLens Vision Analysis - IP:', hashIP(req.ip));
    const startTime = Date.now();
    
    // Appel OpenAI Vision avec gestion d'erreur robuste
    const response = await openai.chat.completions.create({
      model: "gpt-4o", // ModÃ¨le OpenAI le plus rÃ©cent
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: prompt },
            { 
              type: "image_url", 
              image_url: { 
                url: imageData,
                detail: "high"
              } 
            }
          ]
        }
      ],
      max_tokens: 1500,
      temperature: 0.1
    });
    
    const processingTime = Date.now() - startTime;
    
    // Log usage pour monitoring
    const usage = response.usage;
    const cost = calculateOpenAICost('gpt-4o', usage);
    
    await logDodoLensUsage(req.ip, 'vision', {
      tokens: usage.total_tokens,
      cost: cost,
      processing_time_ms: processingTime,
      timestamp: new Date()
    });
    
    console.log(`âœ… Vision analysis success - Tokens: ${usage.total_tokens}, Cost: â‚¬${cost.toFixed(4)}, Time: ${processingTime}ms`);
    
    res.json({
      success: true,
      result: response.choices[0].message.content,
      usage: {
        tokens: usage.total_tokens,
        cost: Math.round(cost * 10000) / 10000, // 4 dÃ©cimales
        processing_time_ms: processingTime
      }
    });
    
  } catch (error) {
    console.error('âŒ OpenAI Vision Error DÃ‰TAILLÃ‰:', error);
    console.error('âŒ Error status:', error.status);
    console.error('âŒ Error message:', error.message);
    console.error('âŒ Error code:', error.code);
    console.error('âŒ Error type:', error.type);
    
    // Gestion des erreurs spÃ©cifiques OpenAI
    if (error.status === 429) {
      return res.status(429).json({ 
        error: 'Limite OpenAI atteinte, rÃ©essayez dans quelques minutes',
        retry_after: 60
      });
    }
    
    if (error.status === 401) {
      return res.status(503).json({ 
        error: 'Configuration OpenAI invalide, contactez le support',
        details: 'ClÃ© API invalide ou expirÃ©e'
      });
    }
    
    if (error.status === 400) {
      return res.status(400).json({ 
        error: 'RequÃªte OpenAI invalide',
        details: error.message
      });
    }
    
    if (error.status === 403) {
      return res.status(403).json({ 
        error: 'AccÃ¨s refusÃ© - VÃ©rifiez les permissions de votre clÃ© OpenAI',
        details: 'ClÃ© n\'a pas accÃ¨s Ã  GPT-4 Vision ou compte sans crÃ©dit'
      });
    }
    
    res.status(500).json({ 
      error: 'Erreur analyse IA',
      details: error.message || 'Erreur interne',
      debug: {
        status: error.status,
        code: error.code,
        type: error.type
      }
    });
  }
});

// ===============================================
// ROUTE 2: TRANSCRIPTION AUDIO (WHISPER)
// ===============================================
router.post('/analyze-audio', dodoLensLimiter, requireOpenAI, upload.single('audioFile'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ 
        error: 'Fichier audio requis (champ: audioFile)' 
      });
    }
    
    console.log(`ðŸ”„ DodoLens Audio Transcription - IP: ${hashIP(req.ip)}, Size: ${(req.file.size / 1024 / 1024).toFixed(2)}MB`);
    const startTime = Date.now();
    
    // PrÃ©paration stream pour OpenAI Whisper
    console.log('ðŸ”§ PrÃ©paration stream audio pour OpenAI Whisper...');
    
    // SOLUTION ULTRA-ROBUSTE: Polyfill File optimisÃ© pour Railway
    console.log('ðŸ”§ CrÃ©ation File polyfill robuste pour Railway...');
    
    // Toujours utiliser notre polyfill pour Ã©viter les warnings expÃ©rimentaux
    globalThis.File = class File {
      constructor(fileBits, fileName, options = {}) {
        this.name = fileName;
        this.type = options.type || '';
        this.lastModified = Date.now();
        
        // CrÃ©er un buffer combinÃ© optimisÃ©
        if (fileBits.length === 1 && Buffer.isBuffer(fileBits[0])) {
          this._buffer = fileBits[0];
          this.size = fileBits[0].length;
        } else {
          const buffers = fileBits.map(bit => {
            if (Buffer.isBuffer(bit)) return bit;
            if (bit instanceof ArrayBuffer) return Buffer.from(bit);
            if (typeof bit === 'string') return Buffer.from(bit);
            return Buffer.from(bit);
          });
          this._buffer = Buffer.concat(buffers);
          this.size = this._buffer.length;
        }
        
        console.log(`ðŸ“¦ File polyfill crÃ©Ã©: ${this.name} (${this.size} bytes, ${this.type})`);
      }
      
      // MÃ©thode stream() compatible OpenAI
      stream() {
        const { Readable } = require('stream');
        const stream = Readable.from(this._buffer);
        
        // PropriÃ©tÃ©s nÃ©cessaires pour OpenAI
        stream.path = this.name;
        stream.filename = this.name;
        stream.mimetype = this.type;
        
        return stream;
      }
      
      // MÃ©thodes Web API standards
      arrayBuffer() {
        return Promise.resolve(this._buffer.buffer.slice(
          this._buffer.byteOffset, 
          this._buffer.byteOffset + this._buffer.byteLength
        ));
      }
      
      text() {
        return Promise.resolve(this._buffer.toString('utf8'));
      }
      
      // MÃ©thode pour rÃ©cupÃ©rer le buffer directement
      buffer() {
        return this._buffer;
      }
    };
    
    console.log('âœ… File polyfill robuste installÃ©');
    
    // Logs dÃ©taillÃ©s du fichier reÃ§u (version ultra-sÃ©curisÃ©e)
    console.log('ðŸ“Š Analyse fichier reÃ§u:', {
      fieldname: req.file.fieldname,
      originalname: req.file.originalname,
      mimetype: req.file.mimetype,
      size: req.file.size,
      buffer_type: typeof req.file.buffer
    });
    
    // Log constructor sÃ©parÃ© pour Ã©viter crash
    try {
      console.log('ðŸ” Buffer constructor:', req.file.buffer.constructor.name);
    } catch (e) {
      console.log('âš ï¸ Impossible de lire constructor:', e.message);
    }
    
    // Validation basique (adaptÃ©e pour Blob)
    if (!req.file.buffer || req.file.size === 0) {
      throw new Error('Fichier audio vide');
    }
    
    if (req.file.size > 25 * 1024 * 1024) {
      throw new Error('Fichier audio trop volumineux (>25MB)');
    }
    
    // SOLUTION DÃ‰FINITIVE: File System temporaire - La seule qui marche avec OpenAI SDK
    console.log('ðŸŽ™ï¸ Utilisation fichier temporaire pour OpenAI compatibility...');
    
    const fs = require('fs');
    const path = require('path');
    const os = require('os');
    
    // DIAGNOSTIC COMPLET et conversion forcÃ©e
    console.log('ðŸ” DIAGNOSTIC req.file.buffer:');
    console.log('  - Type:', typeof req.file.buffer);
    console.log('  - Constructor:', req.file.buffer.constructor.name);
    console.log('  - instanceof Buffer:', req.file.buffer instanceof Buffer);
    console.log('  - Has arrayBuffer method:', typeof req.file.buffer.arrayBuffer === 'function');
    console.log('  - Is array-like:', Array.isArray(req.file.buffer));
    
    let finalBuffer;
    
    // CONVERSION FORCÃ‰E - Toutes les mÃ©thodes
    try {
      if (Buffer.isBuffer(req.file.buffer)) {
        console.log('âœ… DÃ©jÃ  un Buffer Node.js');
        finalBuffer = req.file.buffer;
      } else if (req.file.buffer instanceof ArrayBuffer) {
        console.log('ðŸ”„ Conversion depuis ArrayBuffer...');
        finalBuffer = Buffer.from(req.file.buffer);
      } else if (typeof req.file.buffer.arrayBuffer === 'function') {
        console.log('ðŸ”„ Conversion depuis Blob via arrayBuffer...');
        const arrayBuffer = await req.file.buffer.arrayBuffer();
        finalBuffer = Buffer.from(arrayBuffer);
      } else if (req.file.buffer.buffer) {
        console.log('ðŸ”„ Conversion depuis TypedArray...');
        finalBuffer = Buffer.from(req.file.buffer.buffer);
      } else {
        console.log('ðŸ”„ Conversion gÃ©nÃ©rique...');
        finalBuffer = Buffer.from(req.file.buffer);
      }
      
      console.log('âœ… Conversion rÃ©ussie - Buffer final:', finalBuffer.length, 'bytes');
      
    } catch (convError) {
      console.log('âŒ TOUTES conversions ont Ã©chouÃ©:', convError.message);
      console.log('ðŸ†˜ Type dÃ©taillÃ©:', Object.prototype.toString.call(req.file.buffer));
      throw new Error(`Conversion impossible: ${convError.message}`);
    }
    
    // CrÃ©er fichier temporaire
    const tempFileName = `whisper_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.webm`;
    const tempFilePath = path.join(os.tmpdir(), tempFileName);
    
    console.log('ðŸ’¾ Ã‰criture fichier temporaire:', tempFilePath);
    fs.writeFileSync(tempFilePath, finalBuffer);
    
    console.log('ðŸ“Š Fichier temporaire crÃ©Ã©:', {
      path: tempFilePath,
      size: finalBuffer.length,
      exists: fs.existsSync(tempFilePath)
    });
    
    // Appel OpenAI Whisper avec fichier temporaire (SOLUTION DÃ‰FINITIVE)
    console.log('ðŸš€ DÃ©but appel OpenAI Whisper API...');
    console.log('ðŸ“‹ ParamÃ¨tres Whisper:', {
      model: "whisper-1",
      language: "fr", 
      response_format: "json",
      temperature: 0.1,
      file_path: tempFilePath,
      file_size: finalBuffer.length
    });
    
    let response;
    try {
      // CrÃ©er ReadStream depuis le fichier temporaire (standard Node.js)
      const audioFileStream = fs.createReadStream(tempFilePath);
      audioFileStream.path = tempFilePath; // Important pour OpenAI SDK
      
      console.log('ðŸ“ ReadStream natif crÃ©Ã© depuis fichier temporaire');
      
      response = await openai.audio.transcriptions.create({
        file: audioFileStream,
        model: "whisper-1",
        language: "fr",
        response_format: "json",
        temperature: 0.1
      });
      
      console.log('ðŸŽ‰ RÃ©ponse OpenAI Whisper reÃ§ue!');
      console.log('ðŸ“ Longueur transcription:', response.text.length, 'caractÃ¨res');
      console.log('ðŸ“ Texte transcrit:', response.text);
      
    } catch (whisperApiError) {
      console.error('ðŸ’¥ Erreur OpenAI Whisper API:', {
        message: whisperApiError.message,
        status: whisperApiError.status,
        type: whisperApiError.type,
        error_details: whisperApiError.error || 'N/A'
      });
      throw whisperApiError;
    } finally {
      // Nettoyer le fichier temporaire (TOUJOURS)
      try {
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
          console.log('ðŸ—‘ï¸ Fichier temporaire supprimÃ©:', tempFilePath);
        }
      } catch (cleanupError) {
        console.log('âš ï¸ Erreur suppression fichier temporaire:', cleanupError.message);
      }
    }
    
    // Calcul du temps de traitement et coÃ»t
    const processingTime = Date.now() - startTime;
    const cost = calculateOpenAICost('whisper-1', { file_size: req.file.size });
    
    // Log usage
    await logDodoLensUsage(req.ip, 'whisper', {
      file_size: req.file.size,
      cost: cost,
      processing_time_ms: processingTime,
      transcript_length: response.text.length,
      timestamp: new Date()
    });
    
    console.log(`âœ… Audio transcription success - Text: ${response.text.length} chars, Cost: â‚¬${cost.toFixed(4)}, Time: ${processingTime}ms`);
    
    // Retourner les rÃ©sultats
    res.json({
      success: true,
      transcript: response.text,
      usage: {
        file_size: req.file.size,
        cost: Math.round(cost * 10000) / 10000,
        processing_time_ms: processingTime,
        transcript_length: response.text.length
      }
    });
    
  } catch (error) {
    console.error('âŒ Whisper Error:', error);
    
    if (error.status === 400 && error.message.includes('file')) {
      return res.status(400).json({ 
        error: 'Format audio non supportÃ© ou fichier corrompu' 
      });
    }
    
    res.status(500).json({ 
      error: 'Erreur transcription audio',
      details: process.env.NODE_ENV === 'development' ? error.message : 'Erreur interne'
    });
  }
});

// ===============================================
// ROUTE 3: ANALYSE FUSION GPT-4
// ===============================================
router.post('/analyze-fusion', dodoLensLimiter, requireOpenAI, async (req, res) => {
  try {
    const { visualResults, audioTranscript, prompt } = req.body;
    
    if (!visualResults || !audioTranscript) {
      return res.status(400).json({ 
        error: 'visualResults et audioTranscript requis',
        received: {
          hasVisualResults: !!visualResults,
          hasAudioTranscript: !!audioTranscript
        }
      });
    }
    
    console.log(`ðŸ”„ DodoLens Fusion Analysis - IP: ${hashIP(req.ip)}`);
    const startTime = Date.now();
    
    // Prompt par dÃ©faut optimisÃ©
    const defaultPrompt = `Fusionne intelligemment ces donnÃ©es pour un dÃ©mÃ©nagement DOM-TOM:

OBJETS DÃ‰TECTÃ‰S VISUELLEMENT:
${Array.isArray(visualResults) ? JSON.stringify(visualResults, null, 2) : visualResults}

COMMENTAIRES AUDIO DE L'UTILISATEUR:
"${audioTranscript}"

Retourne UNIQUEMENT un JSON valide avec cette structure:
{
  "objects": [
    {
      "name": "nom de l'objet en franÃ§ais",
      "quantity": nombre_final,
      "volume": volume_en_m3,
      "category": "salon|cuisine|chambre|bureau|autre",
      "confidence": score_0_a_1,
      "source": "vision|audio|fusion"
    }
  ],
  "totalVolume": somme_volumes_m3,
  "confidence": score_global_0_a_1
}

RÃ¨gles:
- Si l'utilisateur dit "je prends" â†’ inclure l'objet
- Si l'utilisateur dit "je laisse" â†’ exclure l'objet  
- Fusionner objets similaires (ex: "canapÃ©" + "canapÃ© 3 places")
- Volumes rÃ©alistes pour DOM-TOM (pas de meubles gÃ©ants)`;
    
    // Appel GPT-4 pour fusion
    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        {
          role: "user",
          content: prompt || defaultPrompt
        }
      ],
      max_tokens: 2000,
      temperature: 0.1
    });
    
    const processingTime = Date.now() - startTime;
    
    // Log usage
    const usage = response.usage;
    const cost = calculateOpenAICost('gpt-4', usage);
    
    await logDodoLensUsage(req.ip, 'fusion', {
      tokens: usage.total_tokens,
      cost: cost,
      processing_time_ms: processingTime,
      timestamp: new Date()
    });
    
    console.log(`âœ… Fusion analysis success - Tokens: ${usage.total_tokens}, Cost: â‚¬${cost.toFixed(4)}, Time: ${processingTime}ms`);
    
    res.json({
      success: true,
      result: response.choices[0].message.content,
      usage: {
        tokens: usage.total_tokens,
        cost: Math.round(cost * 10000) / 10000,
        processing_time_ms: processingTime
      }
    });
    
  } catch (error) {
    console.error('âŒ GPT-4 Fusion Error:', error);
    
    res.status(500).json({ 
      error: 'Erreur fusion IA',
      details: process.env.NODE_ENV === 'development' ? error.message : 'Erreur interne'
    });
  }
});

// ===============================================
// ROUTE 4: STATISTIQUES USAGE (POUR MONITORING)
// ===============================================
router.get('/stats', async (req, res) => {
  try {
    // Statistiques simples du cache/logs
    const stats = {
      service: 'DodoLens Routes',
      status: openai ? 'operational' : 'degraded',
      uptime: Math.round(process.uptime()),
      cache_size: global.dodoLensUsageCache ? global.dodoLensUsageCache.size : 0,
      timestamp: new Date().toISOString(),
      openai: {
        configured: !!openai, // Vraie dÃ©tection basÃ©e sur l'initialisation rÃ©ussie
        initialized: !!openai,
        key_length: (process.env.OPENAI_API_KEY || process.env.OPENAI_KEY || process.env.DODO_OPENAI_KEY || process.env.OPENAI_SECRET)?.length || 0,
        // Debug Railway - Tester tous les noms de variables
        debug_vars: {
          OPENAI_API_KEY: !!process.env.OPENAI_API_KEY,
          OPENAI_KEY: !!process.env.OPENAI_KEY,
          DODO_OPENAI_KEY: !!process.env.DODO_OPENAI_KEY,
          OPENAI_SECRET: !!process.env.OPENAI_SECRET,
          OPENAI_KEY_B64: !!process.env.OPENAI_KEY_B64
        }
      },
      routes: [
        '/api/dodo-lens/analyze-vision',
        '/api/dodo-lens/analyze-audio', 
        '/api/dodo-lens/analyze-fusion',
        '/api/dodo-lens/stats'
      ]
    };
    
    res.json(stats);
  } catch (error) {
    res.status(500).json({ 
      error: 'Erreur rÃ©cupÃ©ration stats',
      details: error.message 
    });
  }
});

// ===============================================
// UTILITAIRES
// ===============================================

// Calcul coÃ»t OpenAI (prix aoÃ»t 2025)
function calculateOpenAICost(model, usage) {
  const prices = {
    'gpt-4o': {
      input: 0.00250 / 1000,  // $2.50 per 1M input tokens
      output: 0.01000 / 1000  // $10.00 per 1M output tokens
    },
    'gpt-4': {
      input: 0.03000 / 1000,  // $30.00 per 1M input tokens
      output: 0.06000 / 1000  // $60.00 per 1M output tokens
    },
    'whisper-1': 0.006 / 60 // $0.006 per minute
  };
  
  if (model === 'whisper-1') {
    // Approximation: 1MB â‰ˆ 1 minute audio
    const estimatedMinutes = usage.file_size / (1024 * 1024);
    return Math.max(0.001, estimatedMinutes * prices['whisper-1']); // Minimum 0.1 centime
  } else {
    const modelPrices = prices[model];
    if (!modelPrices || !usage.prompt_tokens) return 0.001;
    
    return (usage.prompt_tokens * modelPrices.input) + 
           ((usage.completion_tokens || 0) * modelPrices.output);
  }
}

// Log usage en mÃ©moire simple (remplacer par DB si besoin)
async function logDodoLensUsage(ip, type, data) {
  try {
    // Cache global simple pour Ã©viter la crÃ©ation multiple
    if (!global.dodoLensUsageCache) {
      global.dodoLensUsageCache = new Map();
    }
    
    const logEntry = {
      ip_hash: hashIP(ip),
      type,
      ...data
    };
    
    // Stocker avec TTL de 24h
    const key = `${Date.now()}_${type}_${hashIP(ip)}`;
    global.dodoLensUsageCache.set(key, logEntry);
    
    // Console log pour Railway logs
    console.log('ðŸ“Š DodoLens Usage:', logEntry);
    
    // Nettoyage pÃ©riodique (garder que les 1000 derniÃ¨res entrÃ©es)
    if (global.dodoLensUsageCache.size > 1000) {
      const keys = Array.from(global.dodoLensUsageCache.keys()).sort();
      const toDelete = keys.slice(0, keys.length - 1000);
      toDelete.forEach(key => global.dodoLensUsageCache.delete(key));
    }
    
  } catch (error) {
    console.error('Error logging DodoLens usage:', error);
  }
}

// Hash IP pour RGPD
function hashIP(ip) {
  const salt = process.env.IP_SALT || 'dodo-lens-default-salt-2025';
  return crypto.createHash('sha256')
    .update(ip + salt)
    .digest('hex')
    .substring(0, 16);
}

module.exports = router;
